{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Feature Engineering\n",
        "\n",
        "This notebook prepares features for model training by:\n",
        "1. Loading and merging vehicle positions with stop_times\n",
        "2. Extracting all features\n",
        "3. Selecting relevant features for delay prediction\n",
        "4. Preparing training data (X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Feature Engineering - Transit Tracker\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(str(Path('../src').resolve()))\n",
        "from data_utils import (\n",
        "    load_vehicle_positions,\n",
        "    load_gtfs_data,\n",
        "    preprocess_gtfs,\n",
        "    merge_vehicle_positions_with_stop_times\n",
        ")\n",
        "from features import extract_all_features, create_feature_matrix\n",
        "\n",
        "# Set up paths\n",
        "data_dir = Path('../data/raw')\n",
        "processed_dir = Path('../data/processed')\n",
        "processed_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Feature Engineering - Transit Tracker\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Process Full Dataset\n",
        "\n",
        "Load vehicle positions and stop_times, then merge them. For faster processing, you can use a sample.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading vehicle positions from vehicle_positions_rt_rows-11-13.csv...\n",
            "Loaded 574,123 vehicle position records\n",
            "Using sample of 50,000 records\n"
          ]
        }
      ],
      "source": [
        "# Load vehicle positions from multiple files\n",
        "vehicle_positions_files = [\n",
        "    'vehicle_positions_rt_rows-11-13.csv',\n",
        "    'vehicle_positions_rt_rows_fri_11:14.csv'\n",
        "]\n",
        "\n",
        "vehicle_positions_list = []\n",
        "for vehicle_positions_file in vehicle_positions_files:\n",
        "    print(f\"Loading vehicle positions from {vehicle_positions_file}...\")\n",
        "    df = load_vehicle_positions(data_dir / vehicle_positions_file)\n",
        "    print(f\"Loaded {len(df):,} vehicle position records\")\n",
        "    vehicle_positions_list.append(df)\n",
        "\n",
        "# Concatenate all vehicle positions\n",
        "vehicle_positions = pd.concat(vehicle_positions_list, ignore_index=True)\n",
        "print(f\"\\nTotal vehicle position records: {len(vehicle_positions):,}\")\n",
        "\n",
        "# Option: Use a sample for faster processing during development\n",
        "# Remove this line for full dataset processing\n",
        "USE_SAMPLE = True\n",
        "SAMPLE_SIZE = 50000  # Adjust based on your needs\n",
        "\n",
        "if USE_SAMPLE:\n",
        "    vehicle_positions = vehicle_positions.sample(n=min(SAMPLE_SIZE, len(vehicle_positions)), random_state=42)\n",
        "    print(f\"Using sample of {len(vehicle_positions):,} records\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading GTFS stop_times...\n",
            "Loaded 2,098,728 stop_times records\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess GTFS data\n",
        "print(\"\\nLoading GTFS stop_times...\")\n",
        "gtfs_data = load_gtfs_data(data_dir)\n",
        "gtfs_data = preprocess_gtfs(gtfs_data)\n",
        "\n",
        "if 'stop_times' not in gtfs_data:\n",
        "    raise FileNotFoundError(\"stop_times.txt not found!\")\n",
        "\n",
        "print(f\"Loaded {len(gtfs_data['stop_times']):,} stop_times records\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Merging vehicle positions with stop_times...\n",
            "Merge success rate: 100.0%\n",
            "Merged data shape: (50235, 29)\n"
          ]
        }
      ],
      "source": [
        "# Merge vehicle positions with stop_times\n",
        "print(\"\\nMerging vehicle positions with stop_times...\")\n",
        "merged_data = merge_vehicle_positions_with_stop_times(\n",
        "    vehicle_positions,\n",
        "    gtfs_data['stop_times']\n",
        ")\n",
        "\n",
        "merge_rate = merged_data['arrival_time'].notna().sum() / len(merged_data) * 100\n",
        "print(f\"Merge success rate: {merge_rate:.1f}%\")\n",
        "print(f\"Merged data shape: {merged_data.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Extract All Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting features...\n",
            "Features shape: (50235, 66)\n",
            "Total feature columns: 66\n",
            "\n",
            "Feature columns:\n",
            "  1. id\n",
            "  2. trip_id\n",
            "  3. route_id\n",
            "  4. start_date\n",
            "  5. schedule_relationship\n",
            "  6. vehicle_id\n",
            "  7. vehicle_label\n",
            "  8. latitude\n",
            "  9. longitude\n",
            " 10. bearing\n",
            " 11. speed\n",
            " 12. stop_id\n",
            " 13. current_status\n",
            " 14. timestamp\n",
            " 15. current_stop_sequence\n",
            " 16. datetime\n",
            " 17. arrival_time\n",
            " 18. departure_time\n",
            " 19. stop_sequence\n",
            " 20. stop_headsign\n",
            " 21. pickup_type\n",
            " 22. drop_off_type\n",
            " 23. trip_id_event\n",
            " 24. route_code\n",
            " 25. destination_code\n",
            " 26. timepoint\n",
            " 27. bay_num\n",
            " 28. arrival_time_seconds\n",
            " 29. departure_time_seconds\n",
            " 30. hour\n",
            " 31. day_of_week\n",
            " 32. day_of_month\n",
            " 33. month\n",
            " 34. is_weekend\n",
            " 35. is_rush_hour\n",
            " 36. is_morning_rush\n",
            " 37. is_evening_rush\n",
            " 38. time_of_day\n",
            " 39. route_prefix\n",
            " 40. route_suffix\n",
            " 41. route_frequency\n",
            " 42. trip_id_numeric\n",
            " 43. trip_date_suffix\n",
            " 44. vehicle_frequency\n",
            " 45. has_speed\n",
            " 46. is_moving\n",
            " 47. speed_category\n",
            " 48. has_bearing\n",
            " 49. bearing_direction\n",
            " 50. has_location\n",
            " 51. status_stopped\n",
            " 52. status_in_transit\n",
            " 53. status_incoming\n",
            " 54. status_IN_TRANSIT_TO\n",
            " 55. status_STOPPED_AT\n",
            " 56. is_at_stop\n",
            " 57. actual_time_seconds\n",
            " 58. arrival_delay_seconds\n",
            " 59. arrival_delay_minutes\n",
            " 60. is_delayed\n",
            " 61. is_early\n",
            " 62. is_on_time\n",
            " 63. departure_delay_seconds\n",
            " 64. departure_delay_minutes\n",
            " 65. sequence_match\n",
            " 66. sequence_diff\n"
          ]
        }
      ],
      "source": [
        "# Extract all features\n",
        "print(\"\\nExtracting features...\")\n",
        "features_df = extract_all_features(merged_data)\n",
        "\n",
        "print(f\"Features shape: {features_df.shape}\")\n",
        "print(f\"Total feature columns: {len(features_df.columns)}\")\n",
        "\n",
        "# Display feature columns\n",
        "print(\"\\nFeature columns:\")\n",
        "for i, col in enumerate(features_df.columns, 1):\n",
        "    print(f\"{i:3d}. {col}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Select Features for Model Training\n",
        "\n",
        "Select features that are useful for predicting delays. Exclude target variable and non-predictive columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Selected 34 features for training:\n",
            "  1. latitude\n",
            "  2. longitude\n",
            "  3. bearing\n",
            "  4. speed\n",
            "  5. current_stop_sequence\n",
            "  6. stop_sequence\n",
            "  7. route_code\n",
            "  8. timepoint\n",
            "  9. arrival_time_seconds\n",
            " 10. departure_time_seconds\n",
            " 11. is_weekend\n",
            " 12. is_rush_hour\n",
            " 13. is_morning_rush\n",
            " 14. is_evening_rush\n",
            " 15. time_of_day\n",
            " 16. route_frequency\n",
            " 17. vehicle_frequency\n",
            " 18. has_speed\n",
            " 19. is_moving\n",
            " 20. speed_category\n",
            " 21. has_bearing\n",
            " 22. bearing_direction\n",
            " 23. has_location\n",
            " 24. status_stopped\n",
            " 25. status_in_transit\n",
            " 26. status_incoming\n",
            " 27. status_IN_TRANSIT_TO\n",
            " 28. status_STOPPED_AT\n",
            " 29. is_at_stop\n",
            " 30. is_delayed\n",
            " 31. is_early\n",
            " 32. is_on_time\n",
            " 33. sequence_match\n",
            " 34. sequence_diff\n",
            "\n",
            "Feature statistics:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>bearing</th>\n",
              "      <th>speed</th>\n",
              "      <th>current_stop_sequence</th>\n",
              "      <th>stop_sequence</th>\n",
              "      <th>route_code</th>\n",
              "      <th>timepoint</th>\n",
              "      <th>arrival_time_seconds</th>\n",
              "      <th>departure_time_seconds</th>\n",
              "      <th>time_of_day</th>\n",
              "      <th>route_frequency</th>\n",
              "      <th>vehicle_frequency</th>\n",
              "      <th>sequence_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.000000</td>\n",
              "      <td>50235.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>34.054540</td>\n",
              "      <td>-118.303770</td>\n",
              "      <td>94.926052</td>\n",
              "      <td>5.271894</td>\n",
              "      <td>22.727461</td>\n",
              "      <td>22.727461</td>\n",
              "      <td>205.736837</td>\n",
              "      <td>0.394227</td>\n",
              "      <td>23915.186623</td>\n",
              "      <td>23915.198567</td>\n",
              "      <td>14.465680</td>\n",
              "      <td>685.307554</td>\n",
              "      <td>39.810949</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.104681</td>\n",
              "      <td>0.122927</td>\n",
              "      <td>120.473949</td>\n",
              "      <td>6.404499</td>\n",
              "      <td>23.835221</td>\n",
              "      <td>23.835221</td>\n",
              "      <td>228.229345</td>\n",
              "      <td>0.488689</td>\n",
              "      <td>6063.290956</td>\n",
              "      <td>6063.313249</td>\n",
              "      <td>0.808259</td>\n",
              "      <td>321.095439</td>\n",
              "      <td>11.795187</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>33.707020</td>\n",
              "      <td>-118.861170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15360.000000</td>\n",
              "      <td>15360.000000</td>\n",
              "      <td>12.583333</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.989147</td>\n",
              "      <td>-118.377083</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044704</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21420.000000</td>\n",
              "      <td>21420.000000</td>\n",
              "      <td>13.850000</td>\n",
              "      <td>496.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>34.052353</td>\n",
              "      <td>-118.287110</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.788160</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23880.000000</td>\n",
              "      <td>23880.000000</td>\n",
              "      <td>14.550000</td>\n",
              "      <td>640.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>34.105877</td>\n",
              "      <td>-118.237880</td>\n",
              "      <td>181.700000</td>\n",
              "      <td>10.013696</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>233.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>25920.000000</td>\n",
              "      <td>25920.000000</td>\n",
              "      <td>15.150000</td>\n",
              "      <td>916.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>34.327396</td>\n",
              "      <td>-117.910020</td>\n",
              "      <td>360.000000</td>\n",
              "      <td>30.085793</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>950.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>107040.000000</td>\n",
              "      <td>107040.000000</td>\n",
              "      <td>15.733333</td>\n",
              "      <td>1384.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           latitude     longitude       bearing         speed  \\\n",
              "count  50235.000000  50235.000000  50235.000000  50235.000000   \n",
              "mean      34.054540   -118.303770     94.926052      5.271894   \n",
              "std        0.104681      0.122927    120.473949      6.404499   \n",
              "min       33.707020   -118.861170      0.000000      0.000000   \n",
              "25%       33.989147   -118.377083      0.000000      0.044704   \n",
              "50%       34.052353   -118.287110      0.000000      1.788160   \n",
              "75%       34.105877   -118.237880    181.700000     10.013696   \n",
              "max       34.327396   -117.910020    360.000000     30.085793   \n",
              "\n",
              "       current_stop_sequence  stop_sequence    route_code     timepoint  \\\n",
              "count           50235.000000   50235.000000  50235.000000  50235.000000   \n",
              "mean               22.727461      22.727461    205.736837      0.394227   \n",
              "std                23.835221      23.835221    228.229345      0.488689   \n",
              "min                 1.000000       1.000000      2.000000      0.000000   \n",
              "25%                 1.000000       1.000000     55.000000      0.000000   \n",
              "50%                15.000000      15.000000    120.000000      0.000000   \n",
              "75%                38.000000      38.000000    233.000000      1.000000   \n",
              "max               123.000000     123.000000    950.000000      1.000000   \n",
              "\n",
              "       arrival_time_seconds  departure_time_seconds   time_of_day  \\\n",
              "count          50235.000000            50235.000000  50235.000000   \n",
              "mean           23915.186623            23915.198567     14.465680   \n",
              "std             6063.290956             6063.313249      0.808259   \n",
              "min            15360.000000            15360.000000     12.583333   \n",
              "25%            21420.000000            21420.000000     13.850000   \n",
              "50%            23880.000000            23880.000000     14.550000   \n",
              "75%            25920.000000            25920.000000     15.150000   \n",
              "max           107040.000000           107040.000000     15.733333   \n",
              "\n",
              "       route_frequency  vehicle_frequency  sequence_diff  \n",
              "count     50235.000000       50235.000000        50235.0  \n",
              "mean        685.307554          39.810949            0.0  \n",
              "std         321.095439          11.795187            0.0  \n",
              "min          58.000000           1.000000            0.0  \n",
              "25%         496.000000          32.000000            0.0  \n",
              "50%         640.000000          41.000000            0.0  \n",
              "75%         916.000000          48.000000            0.0  \n",
              "max        1384.000000          77.000000            0.0  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define feature columns for model training\n",
        "# Exclude: target variables, IDs, timestamps, and derived delay columns\n",
        "\n",
        "exclude_cols = [\n",
        "    # Target variables\n",
        "    'arrival_delay_minutes', 'arrival_delay_seconds',\n",
        "    'departure_delay_minutes', 'departure_delay_seconds',\n",
        "    'predicted_delay_minutes',\n",
        "    \n",
        "    # IDs and identifiers\n",
        "    'id', 'trip_id', 'route_id', 'vehicle_id', 'vehicle_label',\n",
        "    'stop_id', 'trip_id_numeric', 'trip_date_suffix',\n",
        "    \n",
        "    # Timestamps and dates\n",
        "    'timestamp', 'datetime', 'start_date',\n",
        "    'scheduled_arrival', 'expected_arrival',\n",
        "    'arrival_time', 'departure_time',\n",
        "    \n",
        "    # Status text (we have encoded versions)\n",
        "    'current_status',\n",
        "    \n",
        "    # Other non-predictive\n",
        "    'schedule_relationship', 'stop_headsign',\n",
        "    'pickup_type', 'drop_off_type',\n",
        "]\n",
        "\n",
        "# Get available feature columns\n",
        "available_cols = [col for col in features_df.columns if col not in exclude_cols]\n",
        "\n",
        "# Select numeric and boolean features\n",
        "feature_cols = []\n",
        "for col in available_cols:\n",
        "    dtype = features_df[col].dtype\n",
        "    if dtype in ['int64', 'float64', 'bool'] or dtype.name == 'category':\n",
        "        feature_cols.append(col)\n",
        "\n",
        "print(f\"\\nSelected {len(feature_cols)} features for training:\")\n",
        "for i, col in enumerate(feature_cols, 1):\n",
        "    print(f\"{i:3d}. {col}\")\n",
        "\n",
        "# Display feature statistics\n",
        "print(\"\\nFeature statistics:\")\n",
        "features_df[feature_cols].describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: X=(50235, 34), y=(50235,)\n",
            "\n",
            "Target variable (y) statistics:\n",
            "  Mean: 469.89 minutes\n",
            "  Median: 479.55 minutes\n",
            "  Std: 96.04 minutes\n",
            "  Min: -963.83 minutes\n",
            "  Max: 553.62 minutes\n",
            "\n",
            "Data quality check:\n",
            "  NaN in X: 0\n",
            "  Inf in X: 0\n",
            "  NaN in y: 0\n"
          ]
        }
      ],
      "source": [
        "# Prepare target variable (arrival delay in minutes)\n",
        "# Use actual delay if available, otherwise skip rows without delay\n",
        "if 'arrival_delay_minutes' in features_df.columns:\n",
        "    # Filter rows with valid delay values\n",
        "    valid_mask = features_df['arrival_delay_minutes'].notna()\n",
        "    training_data = features_df[valid_mask].copy()\n",
        "    \n",
        "    y = training_data['arrival_delay_minutes'].values\n",
        "    X = create_feature_matrix(training_data, feature_cols)\n",
        "    \n",
        "    # Ensure X is numeric for NaN/Inf checks\n",
        "    X = X.astype(np.float64, copy=False)\n",
        "    \n",
        "    print(f\"Training data shape: X={X.shape}, y={y.shape}\")\n",
        "    print(f\"\\nTarget variable (y) statistics:\")\n",
        "    print(f\"  Mean: {y.mean():.2f} minutes\")\n",
        "    print(f\"  Median: {np.median(y):.2f} minutes\")\n",
        "    print(f\"  Std: {y.std():.2f} minutes\")\n",
        "    print(f\"  Min: {y.min():.2f} minutes\")\n",
        "    print(f\"  Max: {y.max():.2f} minutes\")\n",
        "    \n",
        "    # Check for any NaN or Inf values\n",
        "    print(f\"\\nData quality check:\")\n",
        "    print(f\"  NaN in X: {np.isnan(X).sum()}\")\n",
        "    print(f\"  Inf in X: {np.isinf(X).sum()}\")\n",
        "    print(f\"  NaN in y: {np.isnan(y).sum()}\")\n",
        "else:\n",
        "    print(\"Warning: No arrival_delay_minutes column found!\")\n",
        "    print(\"Make sure you've merged vehicle positions with stop_times data.\")\n",
        "    X, y = None, None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Save Training Data\n",
        "\n",
        "Save the feature matrix, target variable, and feature column names for model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved training data to: ../data/processed/training_data.csv\n",
            "Shape: (50235, 35)\n",
            "Saved feature columns to: ../data/processed/feature_columns.json\n",
            "Saved full features DataFrame to: ../data/processed/all_features.csv\n"
          ]
        }
      ],
      "source": [
        "if X is not None and y is not None:\n",
        "    # Create DataFrame with features and target\n",
        "    training_df = pd.DataFrame(X, columns=feature_cols)\n",
        "    training_df['arrival_delay_minutes'] = y\n",
        "    \n",
        "    # Save training data\n",
        "    training_data_path = processed_dir / 'training_data.csv'\n",
        "    training_df.to_csv(training_data_path, index=False)\n",
        "    print(f\"\\nSaved training data to: {training_data_path}\")\n",
        "    print(f\"Shape: {training_df.shape}\")\n",
        "    \n",
        "    # Save feature column names for later use\n",
        "    import json\n",
        "    feature_cols_path = processed_dir / 'feature_columns.json'\n",
        "    with open(feature_cols_path, 'w') as f:\n",
        "        json.dump(feature_cols, f)\n",
        "    print(f\"Saved feature columns to: {feature_cols_path}\")\n",
        "    \n",
        "    # Also save the full features DataFrame for reference\n",
        "    features_path = processed_dir / 'all_features.csv'\n",
        "    features_df.to_csv(features_path, index=False)\n",
        "    print(f\"Saved full features DataFrame to: {features_path}\")\n",
        "else:\n",
        "    print(\"\\nCannot save training data - missing X or y\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
